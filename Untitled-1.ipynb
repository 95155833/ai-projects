{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the board\n",
    "board = ['' for _ in range(9)]\n",
    "\n",
    "# Function to print the board\n",
    "def print_board(board):\n",
    "    for i in range(3):\n",
    "        print(board[3*i:3*(i+1)])\n",
    "    print()\n",
    "\n",
    "# Function to check if a move is valid\n",
    "def is_valid_move(board, move):\n",
    "    return board[move] == ''\n",
    "\n",
    "# Function to make a move\n",
    "def make_move(board, move, player):\n",
    "    if is_valid_move(board, move):\n",
    "        board[move] = player\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# Function to check if a player has won\n",
    "def check_win(board, player):\n",
    "    win_conditions = [\n",
    "        [0, 1, 2], [3, 4, 5], [6, 7, 8],  # Rows\n",
    "        [0, 3, 6], [1, 4, 7], [2, 5, 8],  # Columns\n",
    "        [0, 4, 8], [2, 4, 6]              # Diagonals\n",
    "    ]\n",
    "    for condition in win_conditions:\n",
    "        if all(board[i] == player for i in condition):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Function to check if the board is full\n",
    "def is_board_full(board):\n",
    "    return all(cell != '' for cell in board)\n",
    "\n",
    "# Minimax function with Alpha-Beta Pruning\n",
    "def minimax_alpha_beta(board, depth, alpha, beta, is_maximizing):\n",
    "    if check_win(board, 'X'):\n",
    "        return -1\n",
    "    if check_win(board, 'O'):\n",
    "        return 1\n",
    "    if is_board_full(board):\n",
    "        return 0\n",
    "\n",
    "    if is_maximizing:\n",
    "        best_score = -float('inf')\n",
    "        for i in range(9):\n",
    "            if board[i] == '':\n",
    "                board[i] = 'O'\n",
    "                score = minimax_alpha_beta(board, depth + 1, alpha, beta, False)\n",
    "                board[i] = ''\n",
    "                best_score = max(best_score, score)\n",
    "                alpha = max(alpha, score)\n",
    "                if beta <= alpha:\n",
    "                    break\n",
    "        return best_score\n",
    "    else:\n",
    "        best_score = float('inf')\n",
    "        for i in range(9):\n",
    "            if board[i] == '':\n",
    "                board[i] = 'X'\n",
    "                score = minimax_alpha_beta(board, depth + 1, alpha, beta, True)\n",
    "                board[i] = ''\n",
    "                best_score = min(best_score, score)\n",
    "                beta = min(beta, score)\n",
    "                if beta <= alpha:\n",
    "                    break\n",
    "        return best_score\n",
    "\n",
    "# Function to find the best move with Alpha-Beta Pruning\n",
    "def find_best_move_alpha_beta(board):\n",
    "    best_move = None\n",
    "    best_score = -float('inf')\n",
    "    for i in range(9):\n",
    "        if board[i] == '':\n",
    "            board[i] = 'O'\n",
    "            score = minimax_alpha_beta(board, 0, -float('inf'), float('inf'), False)\n",
    "            board[i] = ''\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_move = i\n",
    "    return best_move\n",
    "\n",
    "def play_game():\n",
    "    board = ['' for _ in range(9)]\n",
    "    player_turn = True  # True if it's the human player's turn\n",
    "\n",
    "    while True:\n",
    "        print_board(board)\n",
    "        \n",
    "        if player_turn:\n",
    "            move = int(input(\"Enter your move (0-8): \"))\n",
    "            if make_move(board, move, 'X'):\n",
    "                if check_win(board, 'X'):\n",
    "                    print_board(board)\n",
    "                    print(\"You win!\")\n",
    "                    break\n",
    "                player_turn = False\n",
    "        else:\n",
    "            move = find_best_move_alpha_beta(board)\n",
    "            make_move(board, move, 'O')\n",
    "            if check_win(board, 'O'):\n",
    "                print_board(board)\n",
    "                print(\"AI wins!\")\n",
    "                break\n",
    "            player_turn = True\n",
    "\n",
    "        if is_board_full(board):\n",
    "            print_board(board)\n",
    "            print(\"It's a tie!\")\n",
    "            break\n",
    "\n",
    "play_game()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Dropout, add\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import os\n",
    "import string\n",
    "import pickle\n",
    "\n",
    "images_path = 'path/to/images'\n",
    "captions_path = 'path/to/captions'\n",
    "\n",
    "def load_captions(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        captions = file.read()\n",
    "    return captions\n",
    "\n",
    "def preprocess_captions(captions):\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    captions = captions.lower()\n",
    "    captions = captions.translate(table)\n",
    "    captions = captions.split('\\n')\n",
    "    return captions\n",
    "\n",
    "def preprocess_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = img / 255.0\n",
    "    return img\n",
    "\n",
    "captions = load_captions(captions_path)\n",
    "captions = preprocess_captions(captions)\n",
    "\n",
    "resnet = ResNet50(weights='imagenet')\n",
    "resnet = Model(resnet.input, resnet.layers[-2].output)\n",
    "\n",
    "def extract_features(directory):\n",
    "    features = {}\n",
    "    for img_name in os.listdir(directory):\n",
    "        img_path = os.path.join(directory, img_name)\n",
    "        img = preprocess_image(img_path)\n",
    "        feature = resnet.predict(img, verbose=0)\n",
    "        img_id = img_name.split('.')[0]\n",
    "        features[img_id] = feature\n",
    "    return features\n",
    "\n",
    "features = extract_features(images_path)\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(captions)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "max_length = max(len(caption.split()) for caption in captions)\n",
    "\n",
    "def create_sequences(tokenizer, max_length, desc_list, photo):\n",
    "    X1, X2, y = list(), list(), list()\n",
    "    for desc in desc_list:\n",
    "        seq = tokenizer.texts_to_sequences([desc])[0]\n",
    "        for i in range(1, len(seq)):\n",
    "            in_seq, out_seq = seq[:i], seq[i]\n",
    "            in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
    "            out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
    "            X1.append(photo)\n",
    "            X2.append(in_seq)\n",
    "            y.append(out_seq)\n",
    "    return np.array(X1), np.array(X2), np.array(y)\n",
    "\n",
    "X1_train, X2_train, y_train = list(), list(), list()\n",
    "for key, desc_list in features.items():\n",
    "    photo = features[key][0]\n",
    "    desc_list = [d for d in captions if d.startswith(key)]\n",
    "    in_img, in_seq, out_word = create_sequences(tokenizer, max_length, desc_list, photo)\n",
    "    X1_train.append(in_img)\n",
    "    X2_train.append(in_seq)\n",
    "    y_train.append(out_word)\n",
    "X1_train, X2_train, y_train = np.array(X1_train), np.array(X2_train), np.array(y_train)\n",
    "\n",
    "def define_model(vocab_size, max_length):\n",
    "    inputs1 = Input(shape=(2048,))\n",
    "    fe1 = Dropout(0.5)(inputs1)\n",
    "    fe2 = Dense(256, activation='relu')(fe1)\n",
    "    inputs2 = Input(shape=(max_length,))\n",
    "    se1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)\n",
    "    se2 = Dropout(0.5)(se1)\n",
    "    se3 = LSTM(256)(se2)\n",
    "    decoder1 = add([fe2, se3])\n",
    "    decoder2 = Dense(256, activation='relu')(decoder1)\n",
    "    outputs = Dense(vocab_size, activation='softmax')(decoder2)\n",
    "    model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "model = define_model(vocab_size, max_length)\n",
    "model.summary()\n",
    "\n",
    "epochs = 20\n",
    "batch_size = 64\n",
    "steps = len(captions) // batch_size\n",
    "\n",
    "for i in range(epochs):\n",
    "    generator = data_generator(X1_train, X2_train, y_train, batch_size)\n",
    "    model.fit(generator, epochs=1, steps_per_epoch=steps, verbose=1)\n",
    "\n",
    "model.save('image_captioning_model.h5')\n",
    "with open('tokenizer.pkl', 'wb') as file:\n",
    "    pickle.dump(tokenizer, file)\n",
    "\n",
    "def generate_caption(model, tokenizer, photo, max_length):\n",
    "    in_text = 'startseq'\n",
    "    for i in range(max_length):\n",
    "        sequence = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        sequence = pad_sequences([sequence], maxlen=max_length)\n",
    "        yhat = model.predict([photo, sequence], verbose=0)\n",
    "        yhat = np.argmax(yhat)\n",
    "        word = tokenizer.index_word[yhat]\n",
    "        if word is None:\n",
    "            break\n",
    "        in_text += ' ' + word\n",
    "        if word == 'endseq':\n",
    "            break\n",
    "    return in_text\n",
    "\n",
    "model = tf.keras.models.load_model('image_captioning_model.h5')\n",
    "with open('tokenizer.pkl', 'rb') as file:\n",
    "    tokenizer = pickle.load(file)\n",
    "\n",
    "new_image_path = 'path/to/new/image.jpg'\n",
    "photo = preprocess_image(new_image_path)\n",
    "photo = resnet.predict(photo, verbose=0)\n",
    "caption = generate_caption(model, tokenizer, photo, max_length)\n",
    "print('Caption:', caption)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "import os\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "recognition_model = load_model('path/to/face_recognition_model.h5')\n",
    "\n",
    "def preprocess_image(img, target_size=(160, 160)):\n",
    "    img = cv2.resize(img, target_size)\n",
    "    img = img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = img / 255.0\n",
    "    return img\n",
    "\n",
    "def recognize_face(model, face):\n",
    "    face = preprocess_image(face)\n",
    "    embedding = model.predict(face)[0]\n",
    "    return embedding\n",
    "\n",
    "def load_known_faces(directory):\n",
    "    known_faces = {}\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            img_path = os.path.join(directory, filename)\n",
    "            img = cv2.imread(img_path)\n",
    "            face = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            face_id = filename.split('.')[0]\n",
    "            known_faces[face_id] = recognize_face(recognition_model, face)\n",
    "    return known_faces\n",
    "\n",
    "def find_closest_face(known_faces, embedding):\n",
    "    min_dist = float('inf')\n",
    "    identity = None\n",
    "    for name, known_embedding in known_faces.items():\n",
    "        dist = np.linalg.norm(embedding - known_embedding)\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            identity = name\n",
    "    return identity, min_dist\n",
    "\n",
    "known_faces = load_known_faces('path/to/known_faces')\n",
    "\n",
    "def process_frame(frame):\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x, y, w, h) in faces:\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        embedding = recognize_face(recognition_model, roi_gray)\n",
    "        identity, distance = find_closest_face(known_faces, embedding)\n",
    "        label = identity if distance < 0.6 else \"Unknown\"\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        cv2.putText(frame, label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "    return frame\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame = process_frame(frame)\n",
    "    cv2.imshow('Face Detection and Recognition', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
